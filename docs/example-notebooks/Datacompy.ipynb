{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f47719-21e9-4a99-bb44-73c4f8b99c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datacompy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a405785-0456-4a78-aec8-4e8045d7462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample DataFrames\n",
    "df_a = pd.DataFrame({\n",
    "    'a': [1, 2, 3],\n",
    "    'b': [4, 5, 6],\n",
    "    'c': ['foo', 'foo', 'bar'],\n",
    "    'e': [100, 10, 1]})\n",
    "\n",
    "df_b = pd.DataFrame({\n",
    "    'a': [1, 2, 3],\n",
    "    'b': [4, 5, 7],\n",
    "    'd': ['foo', 'baz', 'baz'],\n",
    "    'f': [100, 10, 1]\n",
    "})  # Notice the difference in the last row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e244121-fa83-49b1-baf9-0ad664e3c9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = datacompy.Compare(\n",
    "    df_a, df_b,\n",
    "    join_columns='A',  # Column to join DataFrames on\n",
    "    abs_tol=0,  # Absolute tolerance\n",
    "    rel_tol=0)  # Relative tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea44ea72-c3f8-4c1b-a3e8-b65db2d1d823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the report\n",
    "#print(comparison.report())\n",
    "#comparison.column_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7cba28-7196-4a48-849b-21711a407ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_join_dfs(df1, df2, cmp):\n",
    "    df1_name = cmp.df1_name\n",
    "    df2_name = cmp.df2_name\n",
    "\n",
    "    col_order = df1.columns.to_list()\n",
    "    for col in df2.columns:\n",
    "        if col in col_order:\n",
    "            continue\n",
    "            \n",
    "        col_order.append(col)\n",
    "    eqs = {}\n",
    "    def get_col_stat(col_name):\n",
    "        for obj in cmp.column_stats:\n",
    "            if obj['column'] == col_name:\n",
    "                return obj\n",
    "        return None\n",
    "            \n",
    "    for col in col_order:\n",
    "        col_stat = get_col_stat(col)\n",
    "        if col_stat:\n",
    "            eqs[col] = {'unequality': col_stat['unequal_cnt']}\n",
    "        else:\n",
    "            if col in df1.columns:\n",
    "                eqs[col] = {'unequality': df1_name}\n",
    "            else:\n",
    "                eqs[col] = {'unequality': df2_name}\n",
    "    ret_df_columns = {}\n",
    "    column_config_overrides = {}\n",
    "\n",
    "    for col in col_order:\n",
    "        eq_col = eqs[col]['unequality']\n",
    "        if eq_col == df1_name:\n",
    "            #it's only in df1\n",
    "            ret_df_columns[col] = df1[col]\n",
    "        elif eq_col == df2_name:\n",
    "            #it's only in df2\n",
    "            ret_df_columns[col] = df2[col]\n",
    "        elif eq_col == 0:\n",
    "            #columns are exactly the same\n",
    "            ret_df_columns[col] = df1[col]\n",
    "        else:\n",
    "            ret_df_columns[col] = df1[col]\n",
    "            #|df2 is a magic value, not a super fan, but it's also unlikely\n",
    "            df2_col_name = col+\"|df2\"\n",
    "            print(\"col\", col, \"df2_cols\", df2.columns)\n",
    "            ret_df_columns[df2_col_name] = df2[col]\n",
    "            \n",
    "            column_config_overrides[df2_col_name] = {'merge_rule': 'hidden'}\n",
    "            #eqs[df2_col_name] = {'merge_rule': 'hidden'}\n",
    "    ret_df = pd.DataFrame(ret_df_columns)\n",
    "    return ret_df, column_config_overrides, eqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3197c5ca-a508-4496-a64d-91a749c3b05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from buckaroo.pluggable_analysis_framework.pluggable_analysis_framework import ColAnalysis\n",
    "from buckaroo import BuckarooWidget\n",
    "from buckaroo.dataflow.dataflow_extras import (\n",
    "    merge_sds, exception_protect)\n",
    "from traitlets import observe\n",
    "\n",
    "def DatacompyBuckaroo(df1, df2):\n",
    "    cmp = datacompy.Compare(\n",
    "        df1, df2,\n",
    "        join_columns='a',  # Column to join DataFrames on\n",
    "        abs_tol=0,  # Absolute tolerance\n",
    "        rel_tol=0)  # Relative tolerance\n",
    "    \n",
    "    def get_df_header(cmp):\n",
    "        df_header = pd.DataFrame({        \n",
    "            \"DataFrame\": [cmp.df1_name, cmp.df2_name],\n",
    "            \"Columns\": [cmp.df1.shape[1], cmp.df2.shape[1]],\n",
    "            \"Rows\": [cmp.df1.shape[0], cmp.df2.shape[0]]}) #, index=['a', 'b'])\n",
    "        return df_header.T\n",
    "    \n",
    "    def column_summary(cmp):\n",
    "        df1_name = cmp.df1_name\n",
    "        df2_name = cmp.df2_name\n",
    "        col_df = pd.DataFrame({\n",
    "            \"Columns in common\":[len(cmp.intersect_columns())],\n",
    "            f\"Columns in {df1_name} not in {df2_name}\":[ cmp.df1_unq_columns().items],\n",
    "            f\"Columns in {df2_name} not in {df1_name}\":[ cmp.df2_unq_columns().items]})\n",
    "        return col_df.T\n",
    "    \n",
    "    def row_summary(cmp):\n",
    "        # write pad arr function to pad array to number of join columns\n",
    "        match_criteria = \"index\"\n",
    "        if not cmp.on_index:\n",
    "            match_criteria = \", \".join(cmp.join_columns)\n",
    "            has_dupes = cmp._any_dupes\n",
    "            df1_name = cmp.df1_name\n",
    "            df2_name = cmp.df2_name\n",
    "    \n",
    "        row_df = pd.DataFrame({\n",
    "            \"Matched On\": [match_criteria],\n",
    "            \"Any Duplicates on match values\": [has_dupes],\n",
    "            \"Number of rows in common\": cmp.intersect_rows.shape[0],\n",
    "            f\"Number of rows in {df1_name} but not in {df2_name}\": cmp.df1_unq_rows.shape[0],\n",
    "            f\"Number of rows in {df2_name} but not in {df1_name}\": cmp.df2_unq_rows.shape[0],\n",
    "            \"Number of rows with some compared columns unequal\": [cmp.intersect_rows.shape[0] - cmp.count_matching_rows()],\n",
    "            \"Number of rows with all compared columns equal\": [cmp.count_matching_rows()]\n",
    "        })\n",
    "        return row_df.T\n",
    "    \n",
    "    def column_matching(cmp):\n",
    "        unequal_count = len([col for col in cmp.column_stats if col[\"unequal_cnt\"] > 0])\n",
    "        equal_count = len([col for col in cmp.column_stats if col[\"unequal_cnt\"] == 0])\n",
    "        total_unequal_count = sum(col[\"unequal_cnt\"] for col in cmp.column_stats)\n",
    "    \n",
    "        col_df = pd.DataFrame({\n",
    "            \"Number of columns compared with some values unequal\": [unequal_count],\n",
    "            \"Number of columns with all values equal\": [equal_count],\n",
    "            \"Total number of values which compare unequal\": [total_unequal_count]})\n",
    "        return col_df.T\n",
    "    \n",
    "    def match_stats(cmp, sample_count=10):\n",
    "        match_stats = []\n",
    "        match_sample = []\n",
    "        any_mismatch = False\n",
    "        for column in cmp.column_stats:\n",
    "            if not column[\"all_match\"]:\n",
    "                any_mismatch = True\n",
    "                match_stats.append({\n",
    "                    \"Column\": column[\"column\"],\n",
    "                    f\"{cmp.df1_name} dtype\": column[\"dtype1\"],\n",
    "                    f\"{cmp.df2_name} dtype\": column[\"dtype2\"],\n",
    "                    \"# Unequal\": column[\"unequal_cnt\"],\n",
    "                    \"Max Diff\": column[\"max_diff\"],\n",
    "                    \"# Null Diff\": column[\"null_diff\"]})\n",
    "            if column[\"unequal_cnt\"] > 0:\n",
    "                match_sample.append(\n",
    "                    cmp.sample_mismatch(\n",
    "                        column[\"column\"], sample_count, for_display=True))\n",
    "    \n",
    "        df_match_stats = pd.DataFrame(match_stats)\n",
    "        df_match_stats.sort_values(\"Column\", inplace=True)\n",
    "        return df_match_stats.T\n",
    "\n",
    "    class DfHeader(ColAnalysis):\n",
    "        @classmethod\n",
    "        def post_process_df(kls, df):\n",
    "            ab = get_df_header(cmp)\n",
    "            print(\"ab\", ab)\n",
    "            return [ab, {\n",
    "        '0': {'_type': 'obj', 'column_config_override': {'displayer_args': {'displayer': 'obj'}}},\n",
    "        #'index': {'_type': 'obj', 'column_config_override': {'displayer_args': {'displayer': 'obj'}}}}\n",
    "            }\n",
    "            ]\n",
    "        post_processing_method = \"Df Headers\"\n",
    "\n",
    "\n",
    "    class ColumnSummary(ColAnalysis):\n",
    "        @classmethod\n",
    "        def post_process_df(kls, df):\n",
    "            col_summary_df = column_summary(cmp)\n",
    "            print(\"col_summary\", col_summary_df)\n",
    "            return [col_summary_df, {}]\n",
    "        post_processing_method = \"Column Summary\"\n",
    "\n",
    "    class RowSummary(ColAnalysis):\n",
    "        @classmethod\n",
    "        def post_process_df(kls, df):\n",
    "            return [row_summary(cmp), {}]\n",
    "        post_processing_method = \"Row Summary\"\n",
    "\n",
    "    class ColumnMatching(ColAnalysis):\n",
    "        @classmethod\n",
    "        def post_process_df(kls, df):\n",
    "            return [column_matching(cmp), {}]\n",
    "        post_processing_method = \"Column Matching\"\n",
    "\n",
    "    class MatchStats(ColAnalysis):\n",
    "        @classmethod\n",
    "        def post_process_df(kls, df):\n",
    "            return [match_stats(cmp), {}]\n",
    "        post_processing_method = \"Match Stats\"\n",
    "\n",
    "    # write class that automatically re-runs styling analysis on post_processed_df\n",
    "    # that way if post_processed_df has different column names then the default dataframe\n",
    "    # the new column names are dipslayed,  tailor made for this situation\n",
    "    # ... or these should be different pinned rows\n",
    "    # nope pinned rows don't work, because then we'd have to change column names still, or have\n",
    "    # a bunch of empty columns\n",
    "        \n",
    "    datacompy_post_processing_klasses = [\n",
    "        DfHeader, ColumnSummary, RowSummary, ColumnMatching, MatchStats]\n",
    "    \n",
    "    base_a_klasses = BuckarooWidget.analysis_klasses.copy()\n",
    "    base_a_klasses.extend(datacompy_post_processing_klasses)\n",
    "    class DatacompyBuckarooWidget(BuckarooWidget):\n",
    "        analysis_klasses = base_a_klasses\n",
    "\n",
    "\n",
    "        #the following should move to \n",
    "        def __init__(self, orig_df, debug=False,\n",
    "                     column_config_overrides=None,\n",
    "                     pinned_rows=None, extra_grid_config=None,\n",
    "                     component_config=None, init_sd=None):\n",
    "            if init_sd is None:\n",
    "                self.init_sd = {}\n",
    "            else:\n",
    "                self.init_sd = init_sd\n",
    "            super().__init__(\n",
    "                orig_df, debug, column_config_overrides, pinned_rows, extra_grid_config, component_config)\n",
    "\n",
    "        @observe('summary_sd')\n",
    "        @exception_protect('merged_sd-protector')\n",
    "        def _merged_sd(self, change):\n",
    "            #slightly inconsitent that processed_sd gets priority over\n",
    "            #summary_sd, given that processed_df is computed first. My\n",
    "            #thinking was that processed_sd has greater total knowledge\n",
    "            #and should supersede summary_sd.\n",
    "            self.merged_sd = merge_sds(\n",
    "                self.init_sd, self.cleaned_sd, self.summary_sd, self.processed_sd)\n",
    "\n",
    "    joined_df, column_config_overrides, init_sd = col_join_dfs(df1, df2, cmp)\n",
    "\n",
    "    histogram_sd =  {\n",
    "        'a': {'h3': {'histogram': [{'name': 'NA', 'NA': 100.0}]}},\n",
    "        'b': {'histogram': {'histogram': [{'name': 1, 'cat_pop': 44.0}, {'name': 'NA', 'NA': 56.0}]}}}\n",
    "\n",
    "    full_init_sd = merge_sds(\n",
    "        {'index':{}}, # we want to make sure index is the first column recognized by buckaroo\n",
    "        init_sd, histogram_sd)\n",
    "\n",
    "    \n",
    "    dcbw = DatacompyBuckarooWidget(\n",
    "        joined_df, column_config_overrides=column_config_overrides, # init_sd=full_init_sd,\n",
    "        pinned_rows=[\n",
    "        {'primary_key_val': 'dtype',           'displayer_args': {'displayer': 'obj'}},\n",
    "        {'primary_key_val': 'histogram',       'displayer_args': {'displayer': 'histogram'}},\n",
    "        #{'primary_key_val': 'histogram',       'displayer_args': {'displayer': 'histogram'}},\n",
    "            \n",
    "        {'primary_key_val': 'unequality',      'displayer_args': {'displayer': 'obj'}},\n",
    "        {'primary_key_val': 'h3', 'displayer_args': {'displayer': 'histogram'}}]\n",
    "            \n",
    "    )\n",
    "\n",
    "    return dcbw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3f6e5c-7c19-47a3-9ddc-c885c5eadaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcbw = DatacompyBuckaroo(df_a, df_b)\n",
    "dcbw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e199ec6-6f35-4827-b15d-d2070418b285",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp = datacompy.Compare(\n",
    "        df_a, df_b,\n",
    "        join_columns='a',  # Column to join DataFrames on\n",
    "        abs_tol=0,  # Absolute tolerance\n",
    "        rel_tol=0)  # Relative tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20b0585-9120-4622-8eaa-97929bbbafb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from buckaroo.customizations.styling import (DefaultMainStyling)\n",
    "class MergingMainStylingAnalysis(DefaultMainStyling):\n",
    "\n",
    "    @classmethod\n",
    "    def style_columns(kls, sd):\n",
    "        print(\"merging main styling\")\n",
    "        ret_col_config = []\n",
    "\n",
    "        #this is necessary for polars to add an index column, which is\n",
    "        #required so that summary_stats makes sense\n",
    "        if 'index' not in sd:\n",
    "            ret_col_config.append({'col_name': 'index', 'displayer_args': {'displayer': 'obj'}})\n",
    "            \n",
    "        for col in sd.keys():\n",
    "            col_meta = sd[col]\n",
    "            if col_meta.get('merge_rule') == 'hidden':\n",
    "                continue\n",
    "            base_style = kls.style_column(col, col_meta)\n",
    "            if 'column_config_override' in col_meta:\n",
    "                #column_config_override, sent by the instantiation, gets set later\n",
    "                base_style.update(col_meta['column_config_override'])\n",
    "            if base_style.get('merge_rule') == 'hidden':\n",
    "                continue\n",
    "\n",
    "            ret_col_config.append(base_style)\n",
    "            \n",
    "        return {\n",
    "            'pinned_rows': kls.pinned_rows,\n",
    "            'column_config': ret_col_config,\n",
    "            'extra_grid_config': kls.extra_grid_config,\n",
    "            'component_config': kls.component_config\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a050be5b-f671-431e-ba68-27cfd569b413",
   "metadata": {},
   "outputs": [],
   "source": [
    "from buckaroo.customizations.analysis import (TypingStats, ComputedDefaultSummaryStats, DefaultSummaryStats)\n",
    "from buckaroo.customizations.histogram import (Histogram)\n",
    "from buckaroo.customizations.styling import (DefaultSummaryStatsStyling, DefaultMainStyling)\n",
    "from buckaroo.dataflow.dataflow import StylingAnalysis\n",
    "base_analysis_klasses = [\n",
    "    TypingStats, DefaultSummaryStats,\n",
    "    Histogram, ComputedDefaultSummaryStats,\n",
    "    StylingAnalysis, DefaultSummaryStats,\n",
    "    DefaultSummaryStatsStyling, \n",
    "    MergingMainStylingAnalysis\n",
    "    #DefaultMainStyling\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780e60c3-2b82-4def-97a1-d00f7c21b777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DatacompyBuckaroo(df1, df2):\n",
    "\n",
    "    \n",
    "    def get_df_header(cmp):\n",
    "        df_header = pd.DataFrame({        \n",
    "            \"DataFrame\": [cmp.df1_name, cmp.df2_name],\n",
    "            \"Columns\": [cmp.df1.shape[1], cmp.df2.shape[1]],\n",
    "            \"Rows\": [cmp.df1.shape[0], cmp.df2.shape[0]]}) #, index=['a', 'b'])\n",
    "        return df_header.T\n",
    "    class DfHeader(ColAnalysis):\n",
    "        @classmethod\n",
    "        def post_process_df(kls, df):\n",
    "            ab = get_df_header(cmp)\n",
    "            print(\"ab\", ab)\n",
    "            base_removes = {}\n",
    "            #create re-run styling helper function that removes all old columns and re-adds\n",
    "            for k in df.columns:\n",
    "                base_removes[k] = {'merge_rule': 'hidden'}\n",
    "            base_removes.update(\n",
    "                {\n",
    "        0: {'_type': 'obj', 'column_config_override': {'displayer_args': {'displayer': 'obj'}}},\n",
    "        1: {'_type': 'obj', 'column_config_override': {'displayer_args': {'displayer': 'obj'}}}})\n",
    "            \n",
    "            return [ab, base_removes]\n",
    "        '''\n",
    "            [\n",
    "        '0': {'_type': 'obj', 'column_config_override': {'displayer_args': {'displayer': 'obj'}}},\n",
    "        '1': {'_type': 'obj', 'column_config_override': {'displayer_args': {'displayer': 'obj'}}},\n",
    "        'a':  {'merge_rule': 'hidden'}}\n",
    "        #'index': {'_type': 'obj', 'column_config_override': {'displayer_args': {'displayer': 'obj'}}}}\n",
    "            \n",
    "            ]\n",
    "        '''\n",
    "        post_processing_method = \"Df Headers\"\n",
    "        \n",
    "    base_a_klasses = base_analysis_klasses.copy()\n",
    "    base_a_klasses.extend([DfHeader, MergingMainStylingAnalysis])\n",
    "    class DatacompyBuckarooWidget(BuckarooWidget):\n",
    "        analysis_klasses = base_a_klasses\n",
    "    joined_df, column_config_overrides, init_sd = col_join_dfs(df1, df2, cmp)\n",
    "    dcbw = DatacompyBuckarooWidget(joined_df, column_config_overrides=column_config_overrides)\n",
    "    return dcbw\n",
    "DatacompyBuckaroo(df_a, df_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798d403c-90c9-462d-94dd-1924a41ded14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcbw.df_display_args['main']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b220da-539c-4ad6-b817-300501f746c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcbw.merged_sd['a']['histogram']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f423e5cf-eaab-4130-9140-de129bbd6e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcbw.df_data_dict['all_stats'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f8f2e5-116c-49a2-a2f7-e2040aa07a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcbw.df_data_dict['all_stats'][25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66949432-b266-43f9-8aea-14c80b12da1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from buckaroo.customizations.styling import DefaultMainStyling\n",
    "class CompareStylingAnalysis(DefaultMainStyling):\n",
    "    @classmethod\n",
    "    def style_columns(kls, sd):\n",
    "        \"\"\"\n",
    "        ret_col_config = []\n",
    "\n",
    "        #this is necessary for polars to add an index column, which is\n",
    "        #required so that summary_stats makes sense\n",
    "        if 'index' not in sd:\n",
    "            ret_col_config.append({'col_name': 'index', 'displayer_args': {'displayer': 'obj'}})\n",
    "            \n",
    "        for col in sd.keys():\n",
    "            col_meta = sd[col]\n",
    "            base_style = kls.style_column(col, col_meta)\n",
    "            if 'column_config_override' in col_meta:\n",
    "                base_style.update(col_meta['column_config_override'])\n",
    "            ret_col_config.append(base_style)\n",
    "\n",
    "        return {\n",
    "            'pinned_rows': kls.pinned_rows,\n",
    "            'column_config': ret_col_config,\n",
    "            'extra_grid_config': kls.extra_grid_config,\n",
    "            'component_config': kls.component_config\n",
    "        }\n",
    "        \"\"\"\n",
    "        retval = \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

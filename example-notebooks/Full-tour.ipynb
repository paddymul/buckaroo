{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install buckaroo\n",
    "try:\n",
    "    from google.colab import output\n",
    "    output.enable_custom_widget_manager()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import buckaroo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstrating Buckaroo on Citibike data.\n",
    "This might take a little time to download\n",
    "\n",
    "*once the view loads click 0's and 1's on the top left to toggle different parts of the UI*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://s3.amazonaws.com/tripdata/201401-citibike-tripdata.zip\")\n",
    "#df = pd.read_csv(\"/Users/paddy/code/example-notebooks/citibike-trips.csv\") #for airplane work\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notice the monospaced numeric formatting in the following dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_df = pd.DataFrame({'a':[111_111,  77_777, 777_777, 1_000_000, 2_111_111, 1_235_999],\n",
    "                       'b':[111_111, 555_555,       0,    28_123,   482_388,     5_666]})\n",
    "num_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms\n",
    "\n",
    "Histograms are built into Buckaroo.  They enable users to quickly identify distributions of data in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#these are some utility functions for generating random distributions\n",
    "#execute and ignore this cell\n",
    "import numpy as np \n",
    "def bimodal(mean_1, mean_2, N, sigma=5):\n",
    "    X1 = np.random.normal(mean_1, sigma, int(N/2))\n",
    "    X2 = np.random.normal(mean_2, sigma, int(N/2))\n",
    "    X = np.concatenate([X1, X2])\n",
    "    return X\n",
    "\n",
    "def rand_cat(named_p, na_per, N):\n",
    "    choices, p = [], []\n",
    "    named_total_per = sum(named_p.values()) + na_per\n",
    "    total_len = int(np.floor(named_total_per * N))\n",
    "    if named_total_per > 0:\n",
    "        for k, v in named_p.items():\n",
    "            choices.append(k)\n",
    "            p.append(v/named_total_per)\n",
    "        choices.append(pd.NA)\n",
    "        p.append(na_per/named_total_per)    \n",
    "        return [np.random.choice(choices, p=p) for k in range(total_len)]\n",
    "    return []\n",
    "\n",
    "def random_categorical(named_p, unique_per, na_per, longtail_per, N):\n",
    "    choice_arr = rand_cat(named_p, na_per, N)\n",
    "    discrete_choice_len = len(choice_arr)\n",
    "\n",
    "    longtail_count = int(np.floor(longtail_per * N))//2\n",
    "    extra_arr = []\n",
    "    for i in range(longtail_count):\n",
    "        extra_arr.append(\"long_%d\" % i)\n",
    "        extra_arr.append(\"long_%d\" % i)\n",
    "\n",
    "    unique_len = N - (len(extra_arr) + discrete_choice_len)\n",
    "    for i in range(unique_len):\n",
    "        extra_arr.append(\"unique_%d\" % i)\n",
    "    all_arr = np.concatenate([choice_arr, extra_arr])\n",
    "    np.random.shuffle(all_arr)\n",
    "    return all_arr    \n",
    "N = 4000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common histogram shapes\n",
    "The following shows the most common shapes you will see in histograms, allowing you to quickly identify patterns\n",
    "\n",
    "Notice the three columns on the right.  Those are categorical histograms as opposed to numerical histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'normal': np.random.normal(25, .3, N),\n",
    "    'exponential' :  np.random.exponential(1.0, N) * 10 ,\n",
    "    'increasing':[i for i in range(N)],\n",
    "    'one': [1]*N,\n",
    "    'dominant_categories':     random_categorical({'foo': .6, 'bar': .25, 'baz':.15}, unique_per=0, na_per=0, longtail_per=0, N=N),\n",
    "    'all_unique_cat': random_categorical({}, unique_per=1, na_per=0, longtail_per=0, N=N)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical histograms\n",
    "Categorical histograms have special colors and patterns for `NA`/`NaN`, `longtail` (values that occur at least twice) and `unique`\n",
    "Categorical histograms are always arranged from most frequent on the left to least frequent on the right.\n",
    "\n",
    "When a column is numerical, but has less than 5 distinct values it is displayed with a categorical histogram, because the numbers were probably flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'all_NA' :          [pd.NA] * N,\n",
    "    'half_NA' :         random_categorical({1: .5}, unique_per=0,   na_per=.5, longtail_per=.0, N=N),\n",
    "    'dominant_categories':     random_categorical({'foo': .6, 'bar': .25, 'baz':.15}, unique_per=0, na_per=0, longtail_per=0, N=N),\n",
    "    'longtail' :        random_categorical({},      unique_per=0,   na_per=.2, longtail_per=.8, N=N),\n",
    "    'longtail_unique' : random_categorical({},      unique_per=0.5, na_per=.0, longtail_per=.5, N=N)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Notice the different distributions of the numeric histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'bimodal' :  bimodal(20,40, N),\n",
    "    'exponential' :  np.random.exponential(1.0, N) * 10 ,\n",
    "    'geometric': np.random.geometric(.2, N) * 10,\n",
    "    'log_normal': np.random.lognormal(25, .3, N),\n",
    "    'normal': np.random.normal(25, .3, N),})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto typing\n",
    "Click over to summary stats and notice the difference between the dtypes on these two tables\n",
    "notice that the birth year for the first table includes `\\n`, autoTyping was turned off for this widget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BuckarooWidget = buckaroo.BuckarooWidget\n",
    "w = BuckarooWidget(df, autoType=False, showCommands=False)\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turning off autocleaning by column\n",
    "This widget has been configured to have the low code UI on by default.\n",
    "Observe that the cleaning operation for each column has been added,\n",
    "and can be removed with the X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "w = BuckarooWidget(df, showCommands=True)\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding a summary stat\n",
    "Buckaroo is completely customizeable.  In the next cells we will add `Variance` to an instance of the BuckarooWidget with the `Pluggable Analysis Framework`.\n",
    "\n",
    "## Why was the Pluggable Analysis Framework built?\n",
    "The `Pluggable Analysis Framework` is engineered to allow summary_stats to be built up piecemeal and incrementally.  Traditionally when writing bits of analysis code, the tendency is to have large brittle functions that do a lot at once.  Adding extra stats either requires copying and pasting the existing function with one small addition, writing each stat independently and possibly recomputing existing stats, having a strictly ordered set of analysis functions, or some complex adhoc argument passing scheme.  I have written adhoc versions in each of these patterns.  Problems are manifest and the aparatus rarely survives even copy-pasting to the next notebook.\n",
    "\n",
    "## How does the Pluggable Analysis Framework work?\n",
    "The `Pluggable Analysis Framework` is built around a DAG of `ColAnalysis` nodes that can depend on other summary stats, and provide one or more summary stats.  Nodes cand be added to the dag with `add_analysis`.  If a class with the same name is inserted into the DAG, the newly inserted node replaces the previous instantiation.  This all facilitates interactive development of analysis functions.  During execution errors are caught and execution proceeds.  This is important because breaking the default dataframe mechanism is a show stopping problem for users\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "w = buckaroo.BuckarooWidget(df, showCommands=False)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from buckaroo.pluggable_analysis_framework import (ColAnalysis)\n",
    "class Variance(ColAnalysis):\n",
    "    provides_summary = [\"variance\"]\n",
    "    requires_summary = [\"mean\"]\n",
    "\n",
    "    @staticmethod\n",
    "    def summary(sampled_ser, summary_ser, ser):\n",
    "        mean = summary_ser.get('mean', False)\n",
    "        arr = ser.to_numpy()\n",
    "            \n",
    "        if mean is pd.NA or mean is np.nan or mean is False:\n",
    "            return dict(variance=\"NA\")\n",
    "        elif mean and pd.api.types.is_integer_dtype(ser):\n",
    "            return dict(variance=np.mean((arr - mean)**2))\n",
    "        elif mean and pd.api.types.is_float_dtype(ser):\n",
    "            return dict(variance=np.mean((arr - mean)**2))\n",
    "        return dict(variance=\"NA\")\n",
    "    summary_stats_display = [\n",
    "        'dtype', 'length', 'nan_count', 'distinct_count', 'empty_count',\n",
    "        'empty_per', 'unique_per', 'nan_per', \n",
    "        'is_numeric', 'is_integer', 'is_datetime',\n",
    "        'mode', 'min', 'max', 'mean', \n",
    "        # we must add variance to the list of summary_stats_display, otherwise our new stat won't be displayed\n",
    "        'variance']\n",
    "w.add_analysis(Variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analysis is added interactively,  toggle the summary stats view on the widget above and notice that `variance` has been added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Unit testing is built in\n",
    "\n",
    "Because there are so many corner cases with numerical code, every time a new summary stat is added, a variety of simple tests are run against it.  This lets you discover bugs earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df = df[:500][df.columns[:4]]\n",
    "# we are going to create, but not display a BuckarooWidget here, we are looking at the error behavior\n",
    "w = buckaroo.BuckarooWidget(small_df, showCommands=False)\n",
    "\n",
    "class Variance(ColAnalysis):\n",
    "    provides_summary = [\"variance\"]\n",
    "    requires_summary = [\"mean\"]\n",
    "    \n",
    "    @staticmethod\n",
    "    def summary(sampled_ser, summary_ser, ser):\n",
    "        mean = summary_ser.get('mean', False)\n",
    "        arr = ser.to_numpy()\n",
    "        #toggle SIMULATED_BUG to easily see behavior with and without a bug\n",
    "        SIMULATED_BUG = True\n",
    "        if SIMULATED_BUG:\n",
    "            if mean in [pd.NA, np.nan, False]:\n",
    "                return dict(variance=\"NA\")\n",
    "        else:\n",
    "            if mean is pd.NA or mean is np.nan or mean is False:\n",
    "                return dict(variance=\"NA\")\n",
    "        if mean and pd.api.types.is_integer_dtype(ser):\n",
    "            return dict(variance=np.mean((arr - mean)**2))\n",
    "        elif mean and pd.api.types.is_float_dtype(ser):\n",
    "            return dict(variance=np.mean((arr - mean)**2))\n",
    "        return dict(variance=\"NA\")\n",
    "    \n",
    "    summary_stats_display = [\n",
    "        'dtype', 'length', 'nan_count', 'distinct_count', 'empty_count',\n",
    "        'empty_per', 'unique_per', 'nan_per', \n",
    "        'is_numeric', 'is_integer', 'is_datetime',\n",
    "        'mode', 'min', 'max', 'mean', \n",
    "        # we must add variance to the list of summary_stats_display, otherwise our new stat won't be displayed\n",
    "        'variance']\n",
    "\n",
    "w.add_analysis(Variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducing errors in the notebook\n",
    "Buckaroo printed reproduction instructions like\n",
    "```\n",
    "from buckaroo.analysis_management import PERVERSE_DF\n",
    "Variance.summary(PERVERSE_DF['all_nan'], pd.Series({'mean': np.nan, }), PERVERSE_DF['all_nan']) # boolean value of NA is ambiguous\n",
    "\n",
    "```\n",
    "\n",
    "`PERVERSE_DF` is a DataFame with all kinds of edgecases that normally trip up numerical code.  You can run the above two lines, and quickly start iterating on your `ColAnalysis` class to fix the error.  Normally adhoc analysis code that iterates over a list of functions blows up in a stack trace referencing an anonymous function in the middle of a for loop called with opaque variables.  Bucakroo gives you a single line that can reproduce the error, with easily inspectable variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiet mode\n",
    "Sometimes you just want to get on with it.  Buckaroo has a setting for that too, set `quiet=True` and unit test errors, and regular processing errors will be silenced.  Not recommended, but if I didn't add it, users would write their own adhoc version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "w = buckaroo.BuckarooWidget(small_df, showCommands=False)\n",
    "#There are errors in the following functions, quiet = True will ignore them\n",
    "\n",
    "def int_digits(n):\n",
    "    if np.isnan(n):\n",
    "        return 1\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    if np.sign(n) == -1:\n",
    "        return int(np.floor(np.log10(np.abs(n)))) + 2\n",
    "    return int(np.floor(np.log10(n)+1))\n",
    "class MinDigits(ColAnalysis):\n",
    "    \n",
    "    requires_summary = [\"min\"]\n",
    "    provides_summary = [\"min_digits\"]\n",
    "    quiet = True\n",
    "    \n",
    "    @staticmethod\n",
    "    def summary(sampled_ser, summary_ser, ser):\n",
    "        is_numeric = pd.api.types.is_numeric_dtype(sampled_ser.dtype)\n",
    "        if is_numeric:\n",
    "            return {\n",
    "                'min_digits':int_digits(summary_ser.loc['min'])}\n",
    "        else:\n",
    "            return {\n",
    "                'min_digits':0}\n",
    "w.add_analysis(MinDigits)\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding a Command to the Low Code UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "w = buckaroo.BuckarooWidget(df[:500], showCommands=True, autoType=False) #turning autoType=False to reduce clutter in the operations\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from buckaroo.all_transforms import Command\n",
    "from buckaroo.lispy import s\n",
    "#Here we start adding commands to the Buckaroo Widget.  Every call to add_command replaces a command with the same name\n",
    "@w.add_command\n",
    "class GroupBy2(Command):\n",
    "    command_default = [s(\"groupby2\"), s('df'), 'col', {}]\n",
    "    command_pattern = [[3, 'colMap', 'colEnum', ['null', 'sum', 'mean', 'median', 'count']]]\n",
    "    @staticmethod \n",
    "    def transform(df, col, col_spec):\n",
    "        grps = df.groupby(col)\n",
    "        df_contents = {}\n",
    "        for k, v in col_spec.items():\n",
    "            if v == \"sum\":\n",
    "                df_contents[k] = grps[k].apply(lambda x: x.sum())\n",
    "            elif v == \"mean\":\n",
    "                df_contents[k] = grps[k].apply(lambda x: x.mean())\n",
    "            elif v == \"median\":\n",
    "                df_contents[k] = grps[k].apply(lambda x: x.median())\n",
    "            elif v == \"count\":\n",
    "                df_contents[k] = grps[k].apply(lambda x: x.count())\n",
    "        return pd.DataFrame(df_contents)\n",
    "\n",
    "    @staticmethod \n",
    "    def transform_to_py(df, col, col_spec):\n",
    "        commands = [\n",
    "            \"    grps = df.groupby('%s')\" % col,\n",
    "            \"    df_contents = {}\"\n",
    "        ]\n",
    "        for k, v in col_spec.items():\n",
    "            if v == \"sum\":\n",
    "                commands.append(\"    paddydf_contents['%s'] = grps['%s'].apply(lambda x: x.sum())\" % (k, k))\n",
    "            elif v == \"mean\":\n",
    "                commands.append(\"    df_contents['%s'] = grps['%s'].apply(lambda x: x.mean())\" % (k, k))\n",
    "            elif v == \"median\":\n",
    "                commands.append(\"    df_contents['%s'] = grps['%s'].apply(lambda x: x.median())\" % (k, k))\n",
    "            elif v == \"count\":\n",
    "                commands.append(\"    df_contents['%s'] = grps['%s'].apply(lambda x: x.count())\" % (k, k))\n",
    "        commands.append(\"    df = pd.DataFrame(df_contents)\")\n",
    "        return \"\\n\".join(commands)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `groupby2` has been added to the commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buckaroo also works on polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "pl.read_csv('/Users/paddy/code/citibike-play/2014-01 - Citi Bike trip data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "buckaroo.debug_packages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a new default dataframe display function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from buckaroo.widget_utils import disable\n",
    "from IPython.core.getipython import get_ipython\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "\n",
    "disable()\n",
    "def my_display_as_buckaroo(df):\n",
    "    w  = BuckarooWidget(df, showCommands=False)\n",
    "    #the analysis we added throws warnings, let's muffle that when used as the default display\n",
    "    warnings.filterwarnings('ignore')\n",
    "    w.add_analysis(Skew)\n",
    "    warnings.filterwarnings('default')\n",
    "    return display(w)\n",
    "\n",
    "def my_enable():\n",
    "    \"\"\"\n",
    "    Automatically use buckaroo to display all DataFrames\n",
    "    instances in the notebook.\n",
    "\n",
    "    \"\"\"\n",
    "    ip = get_ipython()\n",
    "    if ip is None:\n",
    "        print(\"must be running inside ipython to enable default display via enable()\")\n",
    "        return\n",
    "    ip_formatter = ip.display_formatter.ipython_display_formatter\n",
    "    ip_formatter.for_type(pd.DataFrame, my_display_as_buckaroo)\n",
    "my_enable()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

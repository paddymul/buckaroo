{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "375845a4-837a-4a32-a84a-ddb0d546878b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Customizing Buckaroo\n",
    "Buckaroo consists of\n",
    "* The BuckarooWidget which coordinates updates to the frontend, management of analysis, the lowcode UI, and auto_cleaning functionality.\n",
    "* The frontend JS Table - handles display of dataframes, configured through interfaces.\n",
    "* The pluggable analysis framework which orders execution of customized analysis objects, and handles catching errors along with error reporting.\n",
    "* User supplied analyis objects, these operate on the dataframes to build the summary stats table, and configure the frontend display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859de2ef-e86b-49f0-8f43-6c22d9c3ac69",
   "metadata": {},
   "source": [
    "## Adding a Command to the Low Code UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d439a4-3b7b-4e0f-9e52-78523c9d9ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import buckaroo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf47372-c70d-43db-85cb-db6af86ce7d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://s3.amazonaws.com/tripdata/201401-citibike-tripdata.zip\")\n",
    "w = buckaroo.BuckarooWidget(df[:500], showCommands=True, auto_clean=False) #turning autoType=False to reduce clutter in the operations\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5855f6b9-f42b-423b-ae00-09e20188e77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from buckaroo.customizations.all_transforms import Command\n",
    "from buckaroo.jlisp.lispy import s\n",
    "#Here we start adding commands to the Buckaroo Widget.  Every call to add_command replaces a command with the same name\n",
    "@w.add_command\n",
    "class GroupBy3(Command):\n",
    "    command_default = [s(\"groupby3\"), s('df'), 'col', {}]\n",
    "    command_pattern = [[3, 'colMap', 'colEnum', ['null', 'sum', 'mean', 'median', 'count']]]\n",
    "    @staticmethod \n",
    "    def transform(df, col, col_spec):\n",
    "        grps = df.groupby(col)\n",
    "        \n",
    "        df_contents = {}\n",
    "        for k, v in col_spec.items():\n",
    "            if v == \"sum\":\n",
    "                df_contents[k] = grps[k].apply(lambda x: x.sum())\n",
    "            elif v == \"mean\":\n",
    "                df_contents[k] = grps[k].apply(lambda x: x.mean())\n",
    "            elif v == \"median\":\n",
    "                df_contents[k] = grps[k].apply(lambda x: x.median())\n",
    "            elif v == \"count\":\n",
    "                df_contents[k] = grps[k].apply(lambda x: x.count())\n",
    "        return pd.DataFrame(df_contents)\n",
    "\n",
    "    @staticmethod \n",
    "    def transform_to_py(df, col, col_spec):\n",
    "        commands = [\n",
    "            \"    grps = df.groupby('%s')\" % col,\n",
    "            \"    df_contents = {}\"\n",
    "        ]\n",
    "        for k, v in col_spec.items():\n",
    "            if v == \"sum\":\n",
    "                commands.append(\"    paddydf_contents['%s'] = grps['%s'].apply(lambda x: x.sum())\" % (k, k))\n",
    "            elif v == \"mean\":\n",
    "                commands.append(\"    df_contents['%s'] = grps['%s'].apply(lambda x: x.mean())\" % (k, k))\n",
    "            elif v == \"median\":\n",
    "                commands.append(\"    df_contents['%s'] = grps['%s'].apply(lambda x: x.median())\" % (k, k))\n",
    "            elif v == \"count\":\n",
    "                commands.append(\"    df_contents['%s'] = grps['%s'].apply(lambda x: x.count())\" % (k, k))\n",
    "        commands.append(\"    df = pd.DataFrame(df_contents)\")\n",
    "        return \"\\n\".join(commands)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fe04f0-84d4-4e7a-9fef-e61d098da745",
   "metadata": {},
   "source": [
    "Note that `groupby2` has been added to the commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441e9e82-34ec-4359-9000-dff97f537e12",
   "metadata": {},
   "source": [
    "**These docs need updating for 0.5** Take a look at the [customizations](https://github.com/paddymul/buckaroo/tree/main/buckaroo/customizations) directory in the codebase and file some bugs asking for your suggested improvement.  I expect to add a lot more xamples around the 0.6 series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ec3e18-1649-49d2-8e3b-8e93236d93e1",
   "metadata": {},
   "source": [
    "# Adding a summary stat\n",
    "Buckaroo is completely customizeable.  In the next cells we will add `Variance` to an instance of the BuckarooWidget with the `Pluggable Analysis Framework`.\n",
    "\n",
    "## Why was the Pluggable Analysis Framework built?\n",
    "The `Pluggable Analysis Framework` is engineered to allow summary_stats to be built up piecemeal and incrementally.  Traditionally when writing bits of analysis code, the tendency is to have large brittle functions that do a lot at once.  Adding extra stats either requires copying and pasting the existing function with one small addition, writing each stat independently and possibly recomputing existing stats, having a strictly ordered set of analysis functions, or some complex adhoc argument passing scheme.  I have written adhoc versions in each of these patterns.  Problems are manifest and the aparatus rarely survives even copy-pasting to the next notebook.\n",
    "\n",
    "## How does the Pluggable Analysis Framework work?\n",
    "The `Pluggable Analysis Framework` is built around a DAG of `ColAnalysis` nodes that can depend on other summary stats, and provide one or more summary stats.  Nodes cand be added to the dag with `add_analysis`.  If a class with the same name is inserted into the DAG, the newly inserted node replaces the previous instantiation.  This all facilitates interactive development of analysis functions.  During execution errors are caught and execution proceeds.  This is important because breaking the default dataframe mechanism is a show stopping problem for users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fab4e4-5dbb-4b34-ae7c-b4b065d0ed26",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = buckaroo.BuckarooWidget(df, showCommands=False)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d6d3da-cc93-4566-b542-74c8cd5758b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from buckaroo.pluggable_analysis_framework.pluggable_analysis_framework import (ColAnalysis)\n",
    "class Variance(ColAnalysis):\n",
    "    provides_summary = [\"variance\"]\n",
    "    #a bit hacky, the newly added analyis needs to be the last in the dependency chain\n",
    "    requires_summary = [\"histogram\"]\n",
    "\n",
    "    @staticmethod\n",
    "    def series_summary(sampled_ser, ser):\n",
    "        if pd.api.types.is_numeric_dtype(ser):\n",
    "            return dict(variance=ser.var())\n",
    "        return dict(variance=\"NA\")\n",
    "\n",
    "    \n",
    "    summary_stats_display = [\n",
    "        'dtype', 'length', 'nan_count', 'distinct_count', 'empty_count',\n",
    "        'empty_per', 'unique_per', 'nan_per', \n",
    "        'is_numeric', 'is_integer', 'is_datetime',\n",
    "        'mode', 'min', #'max', \n",
    "        'mean', \n",
    "        # we must add variance to the list of summary_stats_display, otherwise our new stat won't be displayed\n",
    "        'variance']\n",
    "w.add_analysis(Variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4451f7-8b2c-4ee5-8beb-930bcf628af4",
   "metadata": {},
   "source": [
    "analysis is added interactively,  toggle the summary stats view on the widget above and notice that `variance` has been added"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdd52ed-443c-4ec3-9063-b067e779cbc4",
   "metadata": {},
   "source": [
    "## Basic Unit testing is built in\n",
    "\n",
    "Because there are so many corner cases with numerical code, every time a new summary stat is added, a variety of simple tests are run against it.  This lets you discover bugs earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3c58fc-b742-4251-9778-e1a33bf4f500",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "small_df = df[:500][df.columns[:4]]\n",
    "# we are going to create, but not display a BuckarooWidget here, we are looking at the error behavior\n",
    "w = buckaroo.BuckarooWidget(small_df, showCommands=False, debug=True)\n",
    "\n",
    "class Variance(ColAnalysis):\n",
    "    provides_summary = [\"variance\"]\n",
    "    requires_summary = [\"mean\"]\n",
    "    \n",
    "    @staticmethod\n",
    "    def summary(sampled_ser, summary_ser, ser):\n",
    "        mean = summary_ser.get('mean', False)\n",
    "        arr = ser.to_numpy()\n",
    "        #toggle SIMULATED_BUG to easily see behavior with and without a bug\n",
    "        SIMULATED_BUG = True\n",
    "        if SIMULATED_BUG:\n",
    "            if mean in [pd.NA, np.nan, False]:\n",
    "                return dict(variance=\"NA\")\n",
    "        else:\n",
    "            if mean is pd.NA or mean is np.nan or mean is False:\n",
    "                return dict(variance=\"NA\")\n",
    "        if mean and pd.api.types.is_integer_dtype(ser):\n",
    "            return dict(variance=np.mean((arr - mean)**2))\n",
    "        elif mean and pd.api.types.is_float_dtype(ser):\n",
    "            return dict(variance=np.mean((arr - mean)**2))\n",
    "        return dict(variance=\"NA\")\n",
    "    \n",
    "    summary_stats_display = [\n",
    "        'dtype', 'length', 'nan_count', 'distinct_count', 'empty_count',\n",
    "        'empty_per', 'unique_per', 'nan_per', \n",
    "        'is_numeric', 'is_integer', 'is_datetime',\n",
    "        'mode', 'min', 'max', 'mean', \n",
    "        # we must add variance to the list of summary_stats_display, otherwise our new stat won't be displayed\n",
    "        'variance']\n",
    "\n",
    "w.add_analysis(Variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8faf375-9aa5-4904-a228-08592cb8ad66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from buckaroo.pluggable_analysis_framework.analysis_management import PERVERSE_DF\n",
    "Variance.summary(PERVERSE_DF['all_nan'], pd.Series({'mean': np.nan, }), PERVERSE_DF['all_nan']) # boolean value of NA is ambiguous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28c3fb7-62bf-48db-ae68-f32a01116628",
   "metadata": {},
   "source": [
    "## Reproducing errors in the notebook\n",
    "Buckaroo printed reproduction instructions like\n",
    "```\n",
    "from buckaroo.pluggable_analysis_framework.analysis_management import PERVERSE_DF\n",
    "Variance.summary(PERVERSE_DF['all_nan'], pd.Series({'mean': np.nan, }), PERVERSE_DF['all_nan']) # boolean value of NA is ambiguous\n",
    "\n",
    "```\n",
    "\n",
    "`PERVERSE_DF` is a DataFame with all kinds of edgecases that normally trip up numerical code.  You can run the above two lines, and quickly start iterating on your `ColAnalysis` class to fix the error.  Normally adhoc analysis code that iterates over a list of functions blows up in a stack trace referencing an anonymous function in the middle of a for loop called with opaque variables.  Bucakroo gives you a single line that can reproduce the error, with easily inspectable variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41b448c-6533-4a1e-a216-cb18da7e20ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from buckaroo.pluggable_analysis_framework.analysis_management import PERVERSE_DF\n",
    "Variance.summary(PERVERSE_DF['all_nan'], pd.Series({'mean': np.nan, }), PERVERSE_DF['all_nan']) # boolean value of NA is ambiguous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e8eb43-79ed-4652-90d0-32f5dd4cb74e",
   "metadata": {},
   "source": [
    "## Quiet mode\n",
    "Sometimes you just want to get on with it.  Buckaroo has a setting for that too, set `quiet=True` and unit test errors, and regular processing errors will be silenced.  Not recommended, but if I didn't add it, users would write their own adhoc version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6163569-9fd7-4692-9f95-e9fadb6615c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = buckaroo.BuckarooWidget(small_df, showCommands=False)\n",
    "#There are errors in the following functions, quiet = True will ignore them\n",
    "\n",
    "def int_digits(n):\n",
    "    if np.isnan(n):\n",
    "        return 1\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    if np.sign(n) == -1:\n",
    "        return int(np.floor(np.log10(np.abs(n)))) + 2\n",
    "    return int(np.floor(np.log10(n)+1))\n",
    "class MinDigits(ColAnalysis):\n",
    "    \n",
    "    requires_summary = [\"min\"]\n",
    "    provides_summary = [\"min_digits\"]\n",
    "    quiet = True\n",
    "    \n",
    "    @staticmethod\n",
    "    def summary(sampled_ser, summary_ser, ser):\n",
    "        is_numeric = pd.api.types.is_numeric_dtype(sampled_ser.dtype)\n",
    "        if is_numeric:\n",
    "            return {\n",
    "                'min_digits':int_digits(summary_ser.loc['min'])}\n",
    "        else:\n",
    "            return {\n",
    "                'min_digits':0}\n",
    "w.add_analysis(MinDigits)\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf664880-3a8e-451d-8ff1-fb657de0a76a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Making a new default dataframe display function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f4d9da-5b06-4d6f-b319-e435e3d62944",
   "metadata": {},
   "outputs": [],
   "source": [
    "from buckaroo.widget_utils import disable\n",
    "from IPython.core.getipython import get_ipython\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "\n",
    "disable()\n",
    "def my_display_as_buckaroo(df):\n",
    "    w  = BuckarooWidget(df, showCommands=False)\n",
    "    #the analysis we added throws warnings, let's muffle that when used as the default display\n",
    "    warnings.filterwarnings('ignore')\n",
    "    w.add_analysis(Skew)\n",
    "    warnings.filterwarnings('default')\n",
    "    return display(w)\n",
    "\n",
    "def my_enable():\n",
    "    \"\"\"\n",
    "    Automatically use buckaroo to display all DataFrames\n",
    "    instances in the notebook.\n",
    "\n",
    "    \"\"\"\n",
    "    ip = get_ipython()\n",
    "    if ip is None:\n",
    "        print(\"must be running inside ipython to enable default display via enable()\")\n",
    "        return\n",
    "    ip_formatter = ip.display_formatter.ipython_display_formatter\n",
    "    ip_formatter.for_type(pd.DataFrame, my_display_as_buckaroo)\n",
    "my_enable()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
